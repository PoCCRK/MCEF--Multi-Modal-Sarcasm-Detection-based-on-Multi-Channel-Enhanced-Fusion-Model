{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d257a71-ce82-4526-adb2-931303ed416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "img_dir = '/hy-tmp/data/dataset_image'\n",
    "train_file = '/hy-tmp/data/data-of-multimodal-sarcasm-detection/text/train.txt'\n",
    "valid_file = '/hy-tmp/data/data-of-multimodal-sarcasm-detection/text/valid2.txt'\n",
    "test_file = '/hy-tmp/data/data-of-multimodal-sarcasm-detection/text/test2.txt'\n",
    "\n",
    "image_files = os.listdir(img_dir)\n",
    "\n",
    "\n",
    "CM_BERT_predicts = '/root/results/CM_BERT_predicts.txt'\n",
    "CM_BERT_TEXT_IN_IMG_TEXT_predicts = '/root/results/CM_BERT_TEXT_IN_IMG_TEXT_predicts.txt'\n",
    "CM_VIT_predicts = '/root/results/CM_VIT_predicts.txt'\n",
    "CM_VIT2_predicts = '/root/results/CM_VIT2_predicts.txt'\n",
    "VIT_64_predicts = '/root/results/VIT_64.txt'\n",
    "CM_GCN_predicts = '/root/results/CM_GCN_predicts.txt'\n",
    "CM_ATTENTION_predicts = '/root/results/CM_ATTENTION_predicts.txt'\n",
    "CM_ATTENTION2_predicts = '/root/results/CM_ATTENTION2_predicts.txt'\n",
    "CM_ATTENTION3_predicts = '/root/results/CM_ATTENTION3_predicts.txt'\n",
    "CM_ATTENTION4_predicts = '/root/results/CM_ATTENTION4_predicts.txt'\n",
    "CM_ATTENTION5_predicts = '/root/results/CM_ATTENTION5_predicts.txt'\n",
    "\n",
    "\n",
    "CM_BERT_val_predicts = '/root/results/CM_BERT_val_predicts.txt'\n",
    "CM_BERT_TEXT_IN_IMG_TEXT_val_predicts = '/root/results/CM_BERT_TEXT_IN_IMG_TEXT_val_predicts.txt'\n",
    "CM_VIT_val_predicts = '/root/results/CM_VIT_val_predicts.txt'\n",
    "CM_VIT2_val_predicts = '/root/results/CM_VIT2_val_predicts.txt'\n",
    "CM_GCN_val_predicts = '/root/results/CM_GCN_val_predicts.txt'\n",
    "CM_ATTENTION_val_predicts = '/root/results/CM_ATTENTION_val_predicts.txt'\n",
    "CM_ATTENTION2_val_predicts = '/root/results/CM_ATTENTION2_val_predicts.txt'\n",
    "CM_ATTENTION3_val_predicts = '/root/results/CM_ATTENTION3_val_predicts.txt'\n",
    "CM_ATTENTION4_val_predicts = '/root/results/CM_ATTENTION4_val_predicts.txt'\n",
    "CM_ATTENTION5_val_predicts = '/root/results/CM_ATTENTION5_val_predicts.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef69533f-d64e-4309-938f-c8882e820e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(data_file):\n",
    "    all_data = {}\n",
    "    with open(data_file,'r',encoding='utf-8') as fin:\n",
    "        lines = fin.readlines()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i]\n",
    "            data = eval(line)\n",
    "            if 'train' in test_file:\n",
    "                img_id,text,label = data\n",
    "            else:\n",
    "                img_id,text,label1,label = data\n",
    "\n",
    "            image_file = img_id+'.jpg'\n",
    "            if image_file in image_files:\n",
    "                all_data[img_id] = {'image_file': image_file, 'label':int(label)}\n",
    "    return all_data\n",
    "\n",
    "def load_predicts(predicts_file, all_data):\n",
    "    logits = {}\n",
    "    with open(predicts_file,'r',encoding='utf-8') as fin:\n",
    "        lines = fin.readlines()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i]\n",
    "            data = line.split()\n",
    "            img_id, predict, label, logit1, logit2 = data\n",
    "            \n",
    "            if img_id in all_data:\n",
    "                logit1 = float(re.findall('-?\\d+(?:\\.\\d+)?', logit1)[0])\n",
    "                logit2 = float(re.findall('-?\\d+(?:\\.\\d+)?', logit2)[0])\n",
    "                logits[img_id] = [logit1, logit2]\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def evaluate_acc_f1(logits_list, all_data, method='mean', weights=None, norm=None):\n",
    "    num_model = len(logits_list)\n",
    "    labels = []\n",
    "    logits_tmp = [[] for i in range(num_model)]\n",
    "    \n",
    "    for img_id in all_data:\n",
    "        label = all_data[img_id]['label']\n",
    "        labels.append(label)\n",
    "        for i in range(num_model):\n",
    "            model_logits = logits_list[i]\n",
    "            logit = model_logits[img_id]\n",
    "            logits_tmp[i].append(logit)\n",
    "    for i in range(num_model):\n",
    "        logits_tmp[i] = np.array(logits_tmp[i])\n",
    "        assert len(labels) == logits_tmp[i].shape[0]\n",
    "    \n",
    "    if norm:\n",
    "        for i in range(num_model):\n",
    "            logits_tmp[i] = normalize(logits_tmp[i], norm=norm, axis=0)\n",
    "    if weights:\n",
    "        assert len(weights) == num_model\n",
    "        for i in range(num_model):\n",
    "            logits_tmp[i] = logits_tmp[i] * weights[i]\n",
    "    \n",
    "    stacked_logits = np.stack(logits_tmp, axis=0)\n",
    "    if method=='sum':\n",
    "        logits = np.sum(stacked_logits, axis=0)\n",
    "    elif method=='max':\n",
    "        logits = np.max(stacked_logits, axis=0)\n",
    "    elif method=='mean':\n",
    "        logits = np.mean(stacked_logits, axis=0)\n",
    "    else:\n",
    "        print('fusion method not find, use sum methon')\n",
    "        logits = np.sum(stacked_logits, axis=0)\n",
    "    \n",
    "    predicts = np.argmax(logits, axis=1)\n",
    "    acc = metrics.accuracy_score(labels, predicts)\n",
    "    f1 = metrics.f1_score(labels, predicts)\n",
    "    precision =  metrics.precision_score(labels, predicts)\n",
    "    recall = metrics.recall_score(labels, predicts)\n",
    "    \n",
    "    return acc, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e670d164-4c3e-471e-969e-2b006e17744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of all test data: 2409\n"
     ]
    }
   ],
   "source": [
    "all_data = load_all_data(test_file)\n",
    "val_all_data = load_all_data(valid_file)\n",
    "\n",
    "print('len of all test data:', len(all_data))\n",
    "\n",
    "CM_BERT_logits = load_predicts(CM_BERT_predicts, all_data)\n",
    "CM_BERT_TEXT_IN_IMG_TEXT_logits = load_predicts(CM_BERT_TEXT_IN_IMG_TEXT_predicts, all_data)\n",
    "CM_VIT_logits = load_predicts(CM_VIT_predicts, all_data)\n",
    "CM_VIT2_logits = load_predicts(CM_VIT2_predicts, all_data)\n",
    "CM_GCN_logits = load_predicts(CM_GCN_predicts, all_data)\n",
    "CM_ATTENTION_logits = load_predicts(CM_ATTENTION_predicts, all_data)\n",
    "CM_ATTENTION2_logits = load_predicts(CM_ATTENTION2_predicts, all_data)\n",
    "CM_ATTENTION3_logits = load_predicts(CM_ATTENTION3_predicts, all_data)\n",
    "CM_ATTENTION4_logits = load_predicts(CM_ATTENTION4_predicts, all_data)\n",
    "CM_ATTENTION5_logits = load_predicts(CM_ATTENTION5_predicts, all_data)\n",
    "\n",
    "CM_BERT_val_logits = load_predicts(CM_BERT_val_predicts, val_all_data)\n",
    "CM_VIT_val_logits = load_predicts(CM_VIT_val_predicts, val_all_data)\n",
    "CM_VIT2_val_logits = load_predicts(CM_VIT2_val_predicts, val_all_data)\n",
    "CM_BERT_TEXT_IN_IMG_TEXT_val_logits = load_predicts(CM_BERT_TEXT_IN_IMG_TEXT_val_predicts, val_all_data)\n",
    "CM_GCN_val_logits = load_predicts(CM_GCN_val_predicts, val_all_data)\n",
    "CM_ATTENTION_val_logits = load_predicts(CM_ATTENTION_val_predicts, val_all_data)\n",
    "CM_ATTENTION2_val_logits = load_predicts(CM_ATTENTION2_val_predicts, val_all_data)\n",
    "CM_ATTENTION3_val_logits = load_predicts(CM_ATTENTION3_val_predicts, val_all_data)\n",
    "CM_ATTENTION4_val_logits = load_predicts(CM_ATTENTION4_val_predicts, val_all_data)\n",
    "CM_ATTENTION5_val_logits = load_predicts(CM_ATTENTION5_val_predicts, val_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1be1bd-9c5a-4440-b22f-b4ed04d3795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8721991701244813, 0.8402489626556017, 0.8359133126934984, 0.8446298227320125)\n",
      "(0.8780082987551867, 0.8473520249221183, 0.843846949327818, 0.8508863399374348)\n",
      "(0.8725612287256123, 0.8415074858027878, 0.8333333333333334, 0.8498435870698644)\n",
      "(0.8779576587795765, 0.8479834539813856, 0.841025641025641, 0.8550573514077163)\n"
     ]
    }
   ],
   "source": [
    "weights = [1.8, 1.0, 2.5, 3.0]\n",
    "weights = [1.0, 1.0, 1.5, 1.6]\n",
    "\n",
    "val_fusion_models = [\n",
    "    # CM_BERT_val_logits,\n",
    "    CM_VIT2_val_logits,\n",
    "    CM_BERT_TEXT_IN_IMG_TEXT_val_logits,\n",
    "    CM_GCN_val_logits,\n",
    "    CM_ATTENTION4_val_logits,\n",
    "                ]\n",
    "fusion_models = [\n",
    "    # CM_BERT_logits,\n",
    "    CM_VIT2_logits,\n",
    "    CM_BERT_TEXT_IN_IMG_TEXT_logits,\n",
    "    CM_GCN_logits,\n",
    "    CM_ATTENTION4_logits,\n",
    "                ]\n",
    "\n",
    "result = evaluate_acc_f1(val_fusion_models, val_all_data, method='mean', weights=None, norm=None)\n",
    "print(result)\n",
    "result = evaluate_acc_f1(val_fusion_models, val_all_data, method='mean', weights=weights, norm='l2')\n",
    "print(result)\n",
    "\n",
    "result = evaluate_acc_f1(fusion_models, all_data, method='mean', weights=None, norm=None)\n",
    "print(result)\n",
    "result = evaluate_acc_f1(fusion_models, all_data, method='mean', weights=weights, norm='l2')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c251a50f-2e79-4b0b-a073-6609074bea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.871315898713159, 0.8383733055265902, 0.8383733055265902, 0.8383733055265902)\n",
      "(0.8700705687007056, 0.8372334893395734, 0.8350622406639004, 0.8394160583941606)\n"
     ]
    }
   ],
   "source": [
    "fusion_models = [\n",
    "    # CM_BERT_logits,\n",
    "    CM_VIT_logits,\n",
    "    CM_BERT_TEXT_IN_IMG_TEXT_logits,\n",
    "    CM_GCN_logits,\n",
    "    CM_ATTENTION5_logits,\n",
    "                ]\n",
    "\n",
    "result = evaluate_acc_f1(fusion_models, all_data, method='mean', weights=None, norm=None)\n",
    "print(result)\n",
    "result = evaluate_acc_f1(fusion_models, all_data, method='mean', weights=None, norm='l1')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d2c46-4ae2-4eb6-9a73-aee92d12effd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
